import { LLMProviderFactory, Message } from '@/lib/llm/providers';
import dotenv from 'dotenv';

// Carregar variÃ¡veis de ambiente
dotenv.config();

async function testProviders() {
  const factory = LLMProviderFactory.getInstance();
  
  // Teste com OpenAI
  console.log('ğŸ¤– Testando OpenAI Provider...');
  try {
    const openaiProvider = factory.createProvider('openai', {
      apiKey: process.env.OPENAI_API_KEY!,
      model: 'gpt-4-turbo-preview'
    });

    const messages: Message[] = [
      { role: 'user', content: 'Explique o conceito de programaÃ§Ã£o funcional em uma frase.' }
    ];

    console.log('ğŸ“¤ Enviando requisiÃ§Ã£o...');
    const response = await openaiProvider.generateResponse(messages);
    console.log('ğŸ“¥ Resposta:', response.content);
    console.log('ğŸ“Š Uso de tokens:', response.usage);
  } catch (error) {
    console.error('âŒ Erro no teste OpenAI:', error);
  }

  // Teste com Anthropic
  console.log('\nğŸ¤– Testando Anthropic Provider...');
  try {
    const anthropicProvider = factory.createProvider('anthropic', {
      apiKey: process.env.ANTHROPIC_API_KEY!,
      model: 'claude-3-opus-20240229'
    });

    const messages: Message[] = [
      { role: 'user', content: 'Explique o conceito de programaÃ§Ã£o funcional em uma frase.' }
    ];

    console.log('ğŸ“¤ Enviando requisiÃ§Ã£o...');
    const response = await anthropicProvider.generateResponse(messages);
    console.log('ğŸ“¥ Resposta:', response.content);
  } catch (error) {
    console.error('âŒ Erro no teste Anthropic:', error);
  }

  // Teste de Stream com OpenAI
  console.log('\nğŸ¤– Testando OpenAI Stream...');
  try {
    const openaiProvider = factory.createProvider('openai', {
      apiKey: process.env.OPENAI_API_KEY!,
      model: 'gpt-4-turbo-preview'
    });

    const messages: Message[] = [
      { role: 'user', content: 'Conte uma histÃ³ria curta sobre um programador e sua IA assistente.' }
    ];

    console.log('ğŸ“¤ Iniciando stream...');
    process.stdout.write('ğŸ“¥ Resposta: ');
    for await (const chunk of openaiProvider.streamResponse(messages)) {
      process.stdout.write(chunk);
    }
    console.log('\nâœ… Stream concluÃ­do');
  } catch (error) {
    console.error('âŒ Erro no teste de stream OpenAI:', error);
  }

  // Teste de Stream com Anthropic
  console.log('\nğŸ¤– Testando Anthropic Stream...');
  try {
    const anthropicProvider = factory.createProvider('anthropic', {
      apiKey: process.env.ANTHROPIC_API_KEY!,
      model: 'claude-3-opus-20240229'
    });

    const messages: Message[] = [
      { role: 'user', content: 'Conte uma histÃ³ria curta sobre um programador e sua IA assistente, mas em portuguÃªs de Portugal.' }
    ];

    console.log('ğŸ“¤ Iniciando stream...');
    process.stdout.write('ğŸ“¥ Resposta: ');
    for await (const chunk of anthropicProvider.streamResponse(messages)) {
      process.stdout.write(chunk);
    }
    console.log('\nâœ… Stream concluÃ­do');
  } catch (error) {
    console.error('âŒ Erro no teste de stream Anthropic:', error);
  }
}

// Executar testes
console.log('ğŸš€ Iniciando testes dos providers...\n');
testProviders(); 