from typing import Optional
from loguru import logger
from fastapi import HTTPException

from .message_service import MessageService
from .llm_service import LLMService
from ..models.message import Message

class ChatService:
    """ServiÃ§o para gerenciar o chat."""
    
    def __init__(self, message_service: MessageService, llm_service: LLMService):
        self.message_service = message_service
        self.llm_service = llm_service
        logger.debug(f"ğŸ”§ ChatService inicializado com: {message_service=}, {llm_service=}")
        
    async def process_message(self, session_id: str, content: str) -> Message:
        """
        Processa uma mensagem do usuÃ¡rio e retorna a resposta.
        
        Args:
            session_id: ID da sessÃ£o do chat
            content: ConteÃºdo da mensagem
            
        Returns:
            Message: Mensagem de resposta do assistente
            
        Raises:
            HTTPException: Se ocorrer algum erro no processamento
        """
        try:
            # ValidaÃ§Ãµes bÃ¡sicas
            if not session_id:
                raise ValueError("ID da sessÃ£o nÃ£o pode estar vazio")
            if not content:
                raise ValueError("ConteÃºdo da mensagem nÃ£o pode estar vazio")
                
            logger.debug(f"ğŸ“¨ Processando mensagem para sessÃ£o {session_id}")
            logger.debug(f"ğŸ“ ConteÃºdo: {content}")
            
            # Salva mensagem do usuÃ¡rio
            logger.debug("ğŸ’¾ Salvando mensagem do usuÃ¡rio...")
            user_message = await self.message_service.save_message(
                session_id=session_id,
                role="user",
                content=content
            )
            logger.debug(f"âœ… Mensagem do usuÃ¡rio salva: {user_message}")
            
            # ObtÃ©m histÃ³rico da conversa
            logger.debug("ğŸ“š Obtendo histÃ³rico da conversa...")
            messages = await self.message_service.get_session_messages(session_id)
            logger.debug(f"âœ… HistÃ³rico obtido: {len(messages)} mensagens")
            
            # Gera resposta do assistente
            logger.debug("ğŸ¤– Gerando resposta do assistente...")
            response = await self.llm_service.get_completion(
                prompt=content,
                context={"messages": messages}
            )
            
            if not response:
                raise ValueError("LLM retornou uma resposta vazia")
                
            logger.debug(f"âœ… Resposta gerada: {response}")
            
            # Salva e retorna resposta
            logger.debug("ğŸ’¾ Salvando resposta do assistente...")
            assistant_message = await self.message_service.save_message(
                session_id=session_id,
                role="assistant", 
                content=response
            )
            logger.debug(f"âœ… Resposta salva: {assistant_message}")
            
            return assistant_message
            
        except ValueError as e:
            logger.error(f"âŒ Erro de validaÃ§Ã£o: {str(e)}")
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            logger.error(f"âŒ Erro ao processar mensagem: {str(e)}")
            logger.exception(e)
            raise HTTPException(
                status_code=500,
                detail="Erro interno ao processar mensagem"
            ) 