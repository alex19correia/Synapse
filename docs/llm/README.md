# Sistema LLM ü§ñ

## Vis√£o Geral

O sistema LLM (Large Language Model) do Synapse Assistant √© respons√°vel pelo processamento de linguagem natural, gera√ß√£o de texto, e integra√ß√£o com modelos de linguagem.

## Componentes

### 1. DeepSeek Client
```python
from src.llm.deepseek_client import DeepSeekClient

client = DeepSeekClient()
response = await client.generate(messages)
```

#### Features
- Gera√ß√£o de texto
- Streaming de respostas
- Cache autom√°tico
- Retry com backoff
- M√©tricas detalhadas
- Extra√ß√£o de entidades
- Sumariza√ß√£o

#### Configura√ß√£o
```python
settings = {
    "model": "deepseek-chat",
    "temperature": 0.7,
    "max_tokens": 1000,
    "cache_ttl": 3600
}
```

### 2. Sistema de Cache

#### Redis Integration
```python
from redis.asyncio import Redis

redis = Redis.from_url(settings.REDIS_URL)
```

#### Cache Key Generation
```python
def get_cache_key(messages, **params):
    data = {
        "messages": messages,
        "params": params
    }
    return f"llm:response:{hash(json.dumps(data))}"
```

#### TTL Management
- Default: 1 hora
- Configur√°vel por opera√ß√£o
- Invalida√ß√£o autom√°tica

### 3. M√©tricas

#### Prometheus Metrics
- `llm_requests_total`
- `llm_tokens_total`
- `llm_latency_seconds`
- `llm_cache_operations`
- `llm_active_requests`

#### Grafana Dashboards
- Lat√™ncia
- Cache hits/misses
- Token usage
- Error rates

### 4. RAG Integration

#### Document Processing
```python
from src.rag.processor import RAGProcessor

processor = RAGProcessor()
chunks = await processor.process_document(text)
```

#### Vector Store
- Qdrant para embeddings
- Chunking autom√°tico
- Metadata tracking
- Similarity search

## Fluxos de Uso

### 1. Gera√ß√£o B√°sica
```python
messages = [
    DeepSeekMessage(role="user", content="Query")
]
response = await client.generate(messages)
```

### 2. Streaming
```python
async for token in client.stream_generate(messages):
    yield token
```

### 3. RAG
```python
# Index document
await processor.add_document(text)

# Query
results = await processor.query(question)
```

## Error Handling

### Retry Logic
```python
async def generate_with_retry(messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await generate(messages)
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            await asyncio.sleep(2 ** attempt)
```

### Error Types
- API Errors
- Rate Limits
- Timeout
- Invalid Input
- Cache Errors

## Performance

### Otimiza√ß√µes
1. Cache em mem√≥ria
2. Connection pooling
3. Batch processing
4. Async operations
5. Request coalescing

### Limites
- Rate limits
- Token limits
- Concurrent requests
- Cache size
- Request timeout

## Monitoramento

### M√©tricas Chave
1. Lat√™ncia (p50, p95, p99)
2. Cache hit ratio
3. Error rate
4. Token usage
5. Request volume

### Alertas
- High latency
- Error spikes
- Cache misses
- Rate limiting
- Token usage

## Seguran√ßa

### Prote√ß√µes
1. Input validation
2. Output sanitization
3. Rate limiting
4. Authentication
5. Encryption

### Dados Sens√≠veis
- API keys
- User data
- Cache data
- Logs

## Manuten√ß√£o

### Rotinas
- Cache cleanup
- Log rotation
- Metric aggregation
- Performance tuning
- Security updates

### Deployment
- Canary releases
- Feature flags
- A/B testing
- Rollback procedures

## Troubleshooting

### Common Issues
1. High latency
   - Check cache hit ratio
   - Monitor API response times
   - Verify connection pooling

2. Cache misses
   - Validate cache keys
   - Check TTL settings
   - Monitor eviction rate

3. Error spikes
   - Check API status
   - Verify rate limits
   - Monitor system resources

## Refer√™ncias

- [DeepSeek API Docs](https://deepseek.com/docs)
- [Redis Documentation](https://redis.io/docs)
- [Qdrant Docs](https://qdrant.tech/docs)
- [FastAPI AsyncIO](https://fastapi.tiangolo.com/async/) 